{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6837e05e",
   "metadata": {},
   "source": [
    "# MFP-GAN Interactive Segmentation\n",
    "This notebook implements a GAN-enhanced version of the CVPR 2024 paper \"Making Full Use of Probability Maps for Interactive Image Segmentation\".\n",
    "\n",
    "**Additions:**\n",
    "- Adversarial training with a PatchGAN-style discriminator\n",
    "- Support for synthetic clicks for interactive simulation\n",
    "- Visualization and metrics logging for reproducibility\n",
    "\n",
    "Author: YOUR NAME  \n",
    "Target: A-category Conference Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb96317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcce4b",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "Use LVIS train2017 and Berkeley dataset. Ensure paths are correct on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b606230",
   "metadata": {},
   "outputs": [],
   "source": [
    "LVIS_PATH = \"/kaggle/input/lvis-v1\"\n",
    "BERKELEY_PATH = \"/kaggle/input/berkeley/berkeley\"\n",
    "\n",
    "TRAIN_JSON = f\"{LVIS_PATH}/lvis_v1_train.json/lvis_v1_train.json\"\n",
    "TRAIN_IMAGES = f\"{LVIS_PATH}/train2017\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40e353",
   "metadata": {},
   "source": [
    "## Model Definitions: Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your full MFPResNetUNet and MFPDiscriminator classes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a2aa1",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        return bce_loss + dice_loss\n",
    "\n",
    "seg_loss_fn = DiceBCELoss()\n",
    "adv_loss_fn = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2303d483",
   "metadata": {},
   "source": [
    "## Training Loop: GAN + Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your `train_gan_segmentation` function here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a793ba",
   "metadata": {},
   "source": [
    "## Synthetic Click Simulation\n",
    "This simulates user guidance points (positive and negative clicks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clicks(mask, num_clicks=5):\n",
    "    pos, neg = [], []\n",
    "    mask_np = mask.squeeze().numpy()\n",
    "    for _ in range(num_clicks):\n",
    "        if mask_np.sum() == 0:\n",
    "            break\n",
    "        y, x = np.where(mask_np == 1)\n",
    "        idx = np.random.choice(len(x))\n",
    "        pos.append((x[idx], y[idx]))\n",
    "        ny, nx = np.where(mask_np == 0)\n",
    "        nidx = np.random.choice(len(nx))\n",
    "        neg.append((nx[nidx], ny[nidx]))\n",
    "    return pos, neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba6e9c",
   "metadata": {},
   "source": [
    "## Evaluation Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318643c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, masks):\n",
    "    preds = (torch.sigmoid(preds) > 0.5).float()\n",
    "    intersection = (preds * masks).sum(dim=(1,2,3))\n",
    "    union = ((preds + masks) > 0).float().sum(dim=(1,2,3))\n",
    "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "    return iou.mean().item()\n",
    "\n",
    "def visualize_debug(images, masks, preds, idx=0):\n",
    "    image = images[idx].permute(1, 2, 0).numpy()\n",
    "    mask = masks[idx][0].numpy()\n",
    "    pred = preds[idx][0].numpy()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Input Image\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred, cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9dd4ce",
   "metadata": {},
   "source": [
    "## Save Predicted Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_mask(img_tensor, mask_tensor, filename_prefix=\"sample\"):\n",
    "    os.makedirs(\"predictions\", exist_ok=True)\n",
    "    img = img_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    mask = (torch.sigmoid(mask_tensor) > 0.5).squeeze().cpu().numpy() * 255\n",
    "    Image.fromarray(mask.astype(np.uint8)).save(f\"predictions/{filename_prefix}_mask.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d1a5b",
   "metadata": {},
   "source": [
    "## üîÅ Run Training + Save Final Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae72841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_loader, generator, discriminator are already defined\n",
    "# Setup optimizer\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=5e-5)\n",
    "\n",
    "# Call training\n",
    "train_gan_segmentation(generator, discriminator, train_loader,\n",
    "                       gen_optimizer, disc_optimizer,\n",
    "                       seg_loss_fn, adv_loss_fn, device,\n",
    "                       epochs=10, adv_weight=0.001)\n",
    "\n",
    "# Save one prediction\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        out = generator(imgs)\n",
    "        save_predicted_mask(imgs[0].cpu(), out[0].cpu(), \"demo\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
